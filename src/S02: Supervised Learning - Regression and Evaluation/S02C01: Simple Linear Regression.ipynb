{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69f3b539",
   "metadata": {},
   "source": [
    "# Simple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157d8427",
   "metadata": {},
   "source": [
    "## Introduction to Regression\n",
    "\n",
    "Regression is a statistical method used to model the relationship between a dependent variable and one or more independent variables. It is widely used in machine learning for predictive modeling and forecasting.\n",
    "\n",
    "The most basic form of regression is **linear regression**, which assumes a linear relationship between the dependent variable and the independent variable(s). In this section, we will focus on simple linear regression, which involves a single independent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381c5c43",
   "metadata": {},
   "source": [
    "## Simple Linear Regression\n",
    "\n",
    "Simple linear regression is a statistical method that models the relationship between a dependent variable and a single independent variable by fitting a linear equation to the observed data.\n",
    "\n",
    "The equation of a simple linear regression model can be expressed as: $$y = \\beta_0 + \\beta_1 x + \\varepsilon$$ where:\n",
    "\n",
    "-   $y$ is the dependent variable (the variable we want to predict),\n",
    "-   $x$ is the independent variable (the feature used for prediction),\n",
    "-   $\\beta_0$ is the $y$-intercept (the value of $y$ when $x = 0$),\n",
    "-   $\\beta_1$ is the slope of the line (the change in $y$ for a one-unit change in $x$),\n",
    "-   $\\varepsilon$ is the error term (the difference between the observed and predicted values)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c9f723",
   "metadata": {},
   "source": [
    "## Assumptions of Simple Linear Regression\n",
    "\n",
    "Simple linear regression makes several key assumptions:\n",
    "\n",
    "1.  **Linearity**: The relationship between the dependent and independent variable is linear.\n",
    "2.  **Independence**: The observations are independent of each other.\n",
    "3.  **Homoscedasticity**: The residuals (errors) have constant variance across all levels of the independent variable.\n",
    "4.  **Normality**: The residuals are normally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c9c1c9",
   "metadata": {},
   "source": [
    "## Evaluation Metrics\n",
    "\n",
    "Evaluation metrics are used to assess the performance of a regression model. Common metrics include:\n",
    "\n",
    "-   **Mean Absolute Error (MAE)**: The average of the absolute differences between predicted and actual values. $$MAE = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|$$ where $y_i$ is the actual value, $\\hat{y}_i$ is the predicted value, and $n$ is the number of observations.\n",
    "-   **Mean Squared Error (MSE)**: The average of the squared differences between predicted and actual values. $$MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$$ where $y_i$ is the actual value, $\\hat{y}_i$ is the predicted value, and $n$ is the number of observations.\n",
    "-   **Root Mean Squared Error (RMSE)**: The square root of the mean squared error, providing an error metric in the same units as the dependent variable. $$RMSE = \\sqrt{MSE}$$ where $MSE$ is the mean squared error.\n",
    "-   **R-squared ($R^2$)**: The proportion of variance in the dependent variable that can be explained by the independent variable(s). It ranges from 0 to 1, where 1 indicates a perfect fit. $$R^2 = 1 - \\frac{SS_{res}}{SS_{tot}}$$ where $SS_{res}$ is the sum of squared residuals and $SS_{tot}$ is the total sum of squares."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbb3c7e",
   "metadata": {},
   "source": [
    "## Practical Demonstration\n",
    "\n",
    "We will now demonstrate how to implement simple linear regression using Python's `scikit-learn` library. We will use a synthetic dataset for this purpose.\n",
    "\n",
    "-   Create a synthetic dataset following the equation $$y = 4 + 3x + \\varepsilon$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dc5e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "X = np.linspace(-2, 2, 100).reshape(-1, 1)  # Independent variable\n",
    "y = 4 + 3 * X + np.random.randn(100, 1)  # Dependent variable with noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef3dff3",
   "metadata": {},
   "source": [
    "-   Create a `pandas.DataFrame` for ease of processing and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e57f2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.DataFrame(np.hstack((X, y)), columns=['X', 'y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e247a1",
   "metadata": {},
   "source": [
    "-   Explore the newly created dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63238ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1117d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dfc869",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7912b7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style='whitegrid')\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=data['X'], y=data['y'])\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.title('Synthetic Dataset: y = 4 + 3X + ε')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b46cd85",
   "metadata": {},
   "source": [
    "-   Split the dataset into training and testing data (80% / 20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48866989",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[['X']], data['y'],\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c10f03",
   "metadata": {},
   "source": [
    "-   Create and fit a simple linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2aeefe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Intercept (β0): {model.intercept_:.2f}\")\n",
    "print(f\"Slope (β1): {model.coef_[0]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79bf326",
   "metadata": {},
   "source": [
    "-   Make predictions and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68685d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "print(f\"R-squared (R^2): {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4899c57f",
   "metadata": {},
   "source": [
    "-   Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4c843c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style='whitegrid')\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=X_test.squeeze(), y=y_test, color='blue', label='Actual')\n",
    "sns.lineplot(x=X_test.squeeze(), y=y_pred, color='red', label='Predicted', linewidth=2)\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.title('Simple Linear Regression')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f54807",
   "metadata": {},
   "source": [
    "## Hands-on Exercises\n",
    "\n",
    "****Exercise 1****: Generate a synthetic dataset with a linear relationship between the independent and dependent variables. Use the following parameters:\n",
    "\n",
    "-   Independent variable: $X$ (uniformly distributed between 0 and 10)\n",
    "-   Dependent variable: $y = 2X + 5 + \\varepsilon$, where $\\varepsilon$ is normally distributed noise.\n",
    "-   Split the dataset into training and testing sets (80% training, 20% testing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd17ece4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic dataset\n",
    "np.random.seed(42)\n",
    "X = 10 * np.random.rand(100, 1)  # Independent variable\n",
    "y = 2 * X + 5 + np.random.randn(100, 1)  # Dependent variable with noise\n",
    "\n",
    "# Create DataFrame\n",
    "data = pd.DataFrame(np.hstack((X, y)), columns=['X', 'y'])\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[['X']], data['y'],\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2b08d4",
   "metadata": {},
   "source": [
    "****Exercise 2****: Fit a simple linear regression model to the training data and evaluate its performance using the following metrics:\n",
    "\n",
    "-   Mean Absolute Error (MAE)\n",
    "-   Mean Squared Error (MSE)\n",
    "-   Root Mean Squared Error (RMSE)\n",
    "-   R-squared ($R^2$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040ef4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = model.score(X_test, y_test)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "print(f\"R-squared (R^2): {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0850c66e",
   "metadata": {},
   "source": [
    "****Exercise 3****: Visualize the results by plotting the actual vs. predicted values on a scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e27d7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=X_test.squeeze(), y=y_test, color='blue', label='Actual')\n",
    "sns.lineplot(x=X_test.squeeze(), y=y_pred, color='red', label='Predicted', linewidth=2)\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.title('Simple Linear Regression - Actual vs Predicted')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c33342f",
   "metadata": {},
   "source": [
    "****Exercise 4****: Explore the impact of outliers on the performance of the simple linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad85286a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "# Generate a dataset with outliers\n",
    "X = 10 * np.random.rand(100, 1)  # Independent variable\n",
    "y = 2 * X + 5 + np.random.randn(100, 1)  # Dependent variable with noise\n",
    "\n",
    "# Introduce outliers\n",
    "y[::20] += 100 * np.random.randn(5, 1)  # Add large noise to every 20th point\n",
    "\n",
    "# Create DataFrame\n",
    "data = pd.DataFrame(np.hstack((X, y)), columns=['X', 'y'])\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[['X']], data['y'],\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "print(f\"R-squared (R^2): {r2:.2f}\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=X_test.squeeze(), y=y_test, color='blue', label='Actual')\n",
    "sns.lineplot(x=X_test.squeeze(), y=y_pred, color='red', label='Predicted', linewidth=2)\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.title('Simple Linear Regression - Actual vs Predicted')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d036de",
   "metadata": {},
   "source": [
    "****Exercise 5****: Implement a function that takes in the independent and dependent variables, fits a simple linear regression model, and returns the evaluation metrics. Use this function to evaluate different synthetic datasets with varying noise levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea801ad",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def evaluate_simple_linear_regression(X, y):\n",
    "    # Split the dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Fit the model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = float(np.sqrt(mse))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    return mae, mse, rmse, r2\n",
    "\n",
    "# Example usage with different noise levels\n",
    "noise_levels = [0.1, 1.0, 5.0]\n",
    "for noise in noise_levels:\n",
    "    X = 10 * np.random.rand(100, 1)  # Independent variable\n",
    "    y = 2 * X + 5 + noise * np.random.randn(100, 1)  # Dependent variable with varying noise\n",
    "    df = pd.DataFrame(np.hstack((X, y)), columns=['X', 'y'])\n",
    "    metrics = evaluate_simple_linear_regression(df[['X']], df[['y']])\n",
    "    print(f\"Noise level: {noise}, Metrics: {metrics}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd8a280",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this section, we introduced simple linear regression, a fundamental technique in machine learning for modeling the relationship between a dependent variable and a single independent variable. We demonstrated how to implement simple linear regression using Python's `scikit-learn` library and evaluated the model's performance using various metrics. We also provided hands-on exercises to reinforce the concepts learned. Simple linear regression serves as a foundation for understanding more complex regression techniques and is widely used in various applications, including finance, economics, and healthcare."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "ML Workshop",
   "language": "python",
   "name": "ml_workshop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
