{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1217939",
   "metadata": {},
   "source": [
    "\n",
    "# Generative Adversarial Networks (GANs)\n",
    "\n",
    "Generative Adversarial Networks (GANs) are a class of machine learning frameworks designed to generate new data samples that resemble a given training dataset. They consist of two neural networks, the **generator** and the **discriminator**, which are trained simultaneously in a game-theoretic framework. The generator creates new data samples, while the discriminator evaluates them against real samples from the training set. The goal of the generator is to produce samples that are indistinguishable from real data, while the discriminator aims to correctly classify samples as real or fake. This adversarial process leads to the generator improving its output quality over time, resulting in realistic data generation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc6718e",
   "metadata": {},
   "source": [
    "## Example: DCGAN on MNIST\n",
    "\n",
    "This example demonstrates how to implement a Deep Convolutional GAN (DCGAN) to generate handwritten digits from the MNIST dataset. The DCGAN architecture uses convolutional layers in both the generator and discriminator to effectively learn spatial hierarchies in the data. The generator takes a random noise vector as input and produces a 28x28 grayscale image, while the discriminator takes an image and outputs a probability indicating whether the image is real (from the dataset) or fake (generated by the generator). The training process involves alternating between training the discriminator to distinguish real from fake images and training the generator to produce images that can fool the discriminator. The result is a trained generator capable of producing realistic handwritten digits that resemble those in the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36251570-bfcc-4998-9ff3-ed605aa0b77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# ───────────────────── 0.  GPU-friendly startup ──────────────────────\n",
    "os.environ[\"TF_GPU_ALLOCATOR\"] = \"cuda_malloc_async\"    # ↓ fragmentation\n",
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "print(gpus)\n",
    "for g in gpus: tf.config.experimental.set_memory_growth(g, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f014821d",
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_DIM, BATCH_SIZE, EPOCHS = 100, 128, 50\n",
    "SAVE_EVERY, GRID_N = 5, 25\n",
    "\n",
    "(x_train, _), _ = tf.keras.datasets.mnist.load_data()\n",
    "x_train = (x_train.astype(\"float32\") - 127.5) / 127.5    # → [-1, 1]\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "dataset = (tf.data.Dataset.from_tensor_slices(x_train).\\\n",
    "           shuffle(60_000).batch(BATCH_SIZE, drop_remainder=True))\n",
    "\n",
    "def build_generator():\n",
    "    return tf.keras.Sequential([\n",
    "        layers.Input((LATENT_DIM,)),\n",
    "        layers.Dense(7*7*256, use_bias=False),\n",
    "        layers.BatchNormalization(), layers.LeakyReLU(0.2),\n",
    "        layers.Reshape((7, 7, 256)),\n",
    "        layers.Conv2DTranspose(128, 5, 1, \"same\", use_bias=False),\n",
    "        layers.BatchNormalization(), layers.LeakyReLU(0.2),\n",
    "        layers.Conv2DTranspose(64, 5, 2, \"same\", use_bias=False),\n",
    "        layers.BatchNormalization(), layers.LeakyReLU(0.2),\n",
    "        layers.Conv2DTranspose(1, 5, 2, \"same\", use_bias=False, activation=\"tanh\")\n",
    "    ], name=\"generator\")\n",
    "\n",
    "def build_discriminator():\n",
    "    return tf.keras.Sequential([\n",
    "        layers.Input((28, 28, 1)),\n",
    "        layers.Conv2D(64, 5, 2, \"same\"),  layers.LeakyReLU(0.2), layers.Dropout(0.3),\n",
    "        layers.Conv2D(128, 5, 2, \"same\"), layers.LeakyReLU(0.2), layers.Dropout(0.3),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(1)\n",
    "    ], name=\"discriminator\")\n",
    "\n",
    "gen, disc = build_generator(), build_discriminator()\n",
    "\n",
    "bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "g_opt = tf.keras.optimizers.Adam(1e-4)\n",
    "d_opt = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "@tf.function\n",
    "def train_step(real_imgs):\n",
    "    noise = tf.random.normal([BATCH_SIZE, LATENT_DIM])\n",
    "\n",
    "    # ---- Discriminator ----\n",
    "    with tf.GradientTape() as d_tape:\n",
    "        fake_imgs = gen(noise, training=True)\n",
    "        real_logits = disc(real_imgs, training=True)\n",
    "        fake_logits = disc(fake_imgs, training=True)\n",
    "\n",
    "        d_loss_real = bce(tf.ones_like(real_logits), real_logits)\n",
    "        d_loss_fake = bce(tf.zeros_like(fake_logits), fake_logits)\n",
    "        d_loss = (d_loss_real + d_loss_fake) * 0.5\n",
    "\n",
    "    d_grads = d_tape.gradient(d_loss, disc.trainable_variables)\n",
    "    d_opt.apply_gradients(zip(d_grads, disc.trainable_variables))\n",
    "\n",
    "    # ---- Generator ----\n",
    "    noise = tf.random.normal([BATCH_SIZE, LATENT_DIM])\n",
    "    with tf.GradientTape() as g_tape:\n",
    "        fake_imgs = gen(noise, training=True)\n",
    "        fake_logits = disc(fake_imgs, training=True)\n",
    "        g_loss = bce(tf.ones_like(fake_logits), fake_logits)   # want \"real\"\n",
    "\n",
    "    g_grads = g_tape.gradient(g_loss, gen.trainable_variables)\n",
    "    g_opt.apply_gradients(zip(g_grads, gen.trainable_variables))\n",
    "    return d_loss, g_loss\n",
    "\n",
    "os.makedirs(\"generated\", exist_ok=True)\n",
    "fixed_noise = tf.random.normal([GRID_N, LATENT_DIM])\n",
    "\n",
    "def save_grid(epoch):\n",
    "    imgs = gen(fixed_noise, training=False)\n",
    "    imgs = (imgs * 127.5 + 127.5).numpy().astype(\"uint8\")\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    for i in range(GRID_N):\n",
    "        plt.subplot(5, 5, i+1)\n",
    "        plt.imshow(imgs[i, :, :, 0], cmap=\"gray\");\n",
    "        plt.axis(\"off\")\n",
    "    plt.tight_layout();\n",
    "    plt.savefig(f\"generated/epoch_{epoch:03d}.png\");\n",
    "    plt.close()\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    for real_batch in dataset:\n",
    "        d_loss, g_loss = train_step(real_batch)\n",
    "    if epoch == 1 or epoch % SAVE_EVERY == 0:\n",
    "        print(f\"Epoch {epoch:>3}/{EPOCHS}  D: {d_loss:.4f}  G: {g_loss:.4f}\")\n",
    "        save_grid(epoch)\n",
    "\n",
    "print(\"Finished training — sample images are in the 'generated/' folder.\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "ML Workshop",
   "language": "python",
   "name": "ml_workshop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
