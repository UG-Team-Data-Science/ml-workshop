{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be71aedf",
   "metadata": {},
   "source": [
    "\n",
    "# Autoencoders\n",
    "\n",
    "Autoencoders are a type of artificial neural network used for unsupervised learning tasks, particularly for dimensionality reduction, feature learning, and data compression. They consist of two main components:\n",
    "\n",
    "-   **Encoder**: Compresses the input data into a lower-dimensional representation (latent space).\n",
    "-   **Decoder**: Reconstructs the original data from the compressed representation.\n",
    "\n",
    "Autoencoders are trained to minimize the difference between the input and the reconstructed output, effectively learning to capture the essential features of the data while discarding noise and irrelevant information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f224867e",
   "metadata": {},
   "source": [
    "## Example: Autoencoder on MNIST Dataset\n",
    "\n",
    "To illustrate the use of autoencoders, we can apply them to the MNIST dataset, which consists of handwritten digits. The goal is to compress the images into a lower-dimensional representation and then reconstruct the original images.\n",
    "\n",
    "-   Load the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f552230",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1)).astype('float32') / 255.0\n",
    "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1)).astype('float32') / 255.0\n",
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd46379",
   "metadata": {},
   "source": [
    "-   Visualize some samples from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09464b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some samples from the dataset\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 4))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(X_train[i].reshape(28, 28), cmap='gray')\n",
    "    plt.title(f'Label: {y_train[i]}')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104a307e",
   "metadata": {},
   "source": [
    "-   Define the autoencoder architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fadf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Reshape\n",
    "\n",
    "# Define the encoder\n",
    "input_img = Input(shape=(28, 28, 1))\n",
    "x = Flatten()(input_img)\n",
    "encoded = Dense(64, activation='relu')(x)\n",
    "\n",
    "# Define the decoder\n",
    "x = Dense(28 * 28 * 1, activation='sigmoid')(encoded)\n",
    "decoded = Reshape((28, 28, 1))(x)\n",
    "\n",
    "# Create the autoencoder model\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a500e5d",
   "metadata": {},
   "source": [
    "-   Train the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274e4965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the autoencoder\n",
    "autoencoder.fit(X_train,\n",
    "                X_train,\n",
    "                epochs=50,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_split=0.2)\n",
    "print(\"Autoencoder training completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a84b8c7",
   "metadata": {},
   "source": [
    "-   Evaluate the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23f5ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the autoencoder\n",
    "import numpy as np\n",
    "reconstruction = autoencoder.predict(X_test)\n",
    "reconstruction_error = np.mean(np.square(X_test - reconstruction))\n",
    "print(f'Reconstruction Error: {reconstruction_error:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d927f7",
   "metadata": {},
   "source": [
    "-   Visualize the reconstructed images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb68a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the original and reconstructed images\n",
    "n = 10  # Number of images to visualize\n",
    "plt.figure(figsize=(10, 4))\n",
    "for i in range(n):\n",
    "    # Original image\n",
    "    plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(X_test[i].reshape(28, 28), cmap='gray')\n",
    "    plt.title(f'Original: {y_test[i]}')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Reconstructed image\n",
    "    plt.subplot(2, n, i + n + 1)\n",
    "    plt.imshow(reconstruction[i].reshape(28, 28), cmap='gray')\n",
    "    plt.title('Reconstructed')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c850aa",
   "metadata": {},
   "source": [
    "-   Save the autoencoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2be5ad",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Save the autoencoder model\n",
    "autoencoder.save('autoencoder_mnist.h5')\n",
    "print(\"Autoencoder model saved as 'autoencoder_mnist.h5'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d994b96",
   "metadata": {},
   "source": [
    "## Hands-on Exercise\n",
    "\n",
    "Repeat the above steps with the CIFAR-10 dataset, which consists of 32x32 color images in 10 classes. The goal is to compress the images into a lower-dimensional representation and then reconstruct the original images.\n",
    "\n",
    "-   Load the CIFAR-10 dataset\n",
    "-   Visualize some samples from the CIFAR-10 dataset\n",
    "-   Define the autoencoder architecture for CIFAR-10\n",
    "-   Train the autoencoder on CIFAR-10\n",
    "-   Evaluate the autoencoder on CIFAR-10\n",
    "-   Visualize the reconstructed images from CIFAR-10"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "ML Workshop",
   "language": "python",
   "name": "ml_workshop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
