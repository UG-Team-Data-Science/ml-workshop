{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa9ec796",
   "metadata": {},
   "source": [
    "\n",
    "# Recurrent Neural Networks (RNNs)\n",
    "\n",
    "Recurrent Neural Networks (RNNs) are a class of artificial neural networks designed for processing sequential data. Unlike traditional feedforward neural networks, RNNs have connections that loop back on themselves, allowing them to maintain a hidden state that can capture information about previous inputs in the sequence.\n",
    "\n",
    "RNNs are particularly useful for tasks such as time series prediction, natural language processing, and speech recognition, where the order and context of the data points are crucial for understanding the underlying patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db872dfd",
   "metadata": {},
   "source": [
    "## Example: LSTM to Predict Sine Wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20472717",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate a noisy sine-wave dataset\n",
    "np.random.seed(42)\n",
    "TIMESTEPS = 50        # input sequence length\n",
    "TOTAL_POINTS = 2000   # total sine points\n",
    "TEST_SPLIT = 0.2\n",
    "\n",
    "x = np.linspace(0, 50, TOTAL_POINTS)\n",
    "sine = np.sin(x) + 0.1 * np.random.randn(TOTAL_POINTS)  # add some noise\n",
    "\n",
    "# Transform the data into (samples, timesteps, features)\n",
    "def make_dataset(series, window):\n",
    "    X, y = [], []\n",
    "    for i in range(len(series) - window):\n",
    "        X.append(series[i : i + window])\n",
    "        y.append(series[i + window])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X, y = make_dataset(sine, TIMESTEPS)\n",
    "X = X[..., np.newaxis]   # shape â†’ (samples, timesteps, 1)\n",
    "y = y[..., np.newaxis]\n",
    "\n",
    "# Train / validation split\n",
    "split_idx = int(len(X) * (1 - TEST_SPLIT))\n",
    "X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "\n",
    "# Define a simple RNN model (or LSTM)\n",
    "model = Sequential([\n",
    "    LSTM(64, activation=\"tanh\", input_shape=(TIMESTEPS, 1)),\n",
    "    Dense(1)                      # one-step forecast\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "model.summary()\n",
    "\n",
    "# Train\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=20,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Predict the test set\n",
    "preds = model.predict(X_test).squeeze()\n",
    "\n",
    "# Plot actual vs. predicted\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(range(len(y_test)), y_test.squeeze(), label=\"Actual\")\n",
    "plt.plot(range(len(preds)), preds, label=\"Predicted\", linestyle=\"--\")\n",
    "plt.title(\"RNN one-step forecast on noisy sine wave\")\n",
    "plt.xlabel(\"Time step\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "ML Workshop",
   "language": "python",
   "name": "ml_workshop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
