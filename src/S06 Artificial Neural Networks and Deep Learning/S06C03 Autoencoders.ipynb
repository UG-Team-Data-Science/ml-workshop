{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be71aedf",
   "metadata": {},
   "source": [
    "\n",
    "# Autoencoders\n",
    "\n",
    "Autoencoders are a type of artificial neural network used for unsupervised learning tasks, particularly for dimensionality reduction, feature learning, and data compression. They consist of two main components:\n",
    "\n",
    "-   **Encoder**: Compresses the input data into a lower-dimensional representation (latent space).\n",
    "-   **Decoder**: Reconstructs the original data from the compressed representation.\n",
    "\n",
    "Autoencoders are trained to minimize the difference between the input and the reconstructed output, effectively learning to capture the essential features of the data while discarding noise and irrelevant information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f224867e",
   "metadata": {},
   "source": [
    "## Example: Autoencoder on MNIST Dataset\n",
    "\n",
    "To illustrate the use of autoencoders, we can apply them to the MNIST dataset, which consists of handwritten digits. The goal is to compress the images into a lower-dimensional representation and then reconstruct the original images.\n",
    "\n",
    "-   Load the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f552230",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1)).astype('float32') / 255.0\n",
    "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1)).astype('float32') / 255.0\n",
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd46379",
   "metadata": {},
   "source": [
    "-   Visualize some samples from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09464b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some samples from the dataset\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 4))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(X_train[i].reshape(28, 28), cmap='gray')\n",
    "    plt.title(f'Label: {y_train[i]}')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104a307e",
   "metadata": {},
   "source": [
    "-   Define the autoencoder architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fadf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Reshape\n",
    "\n",
    "# Define the encoder\n",
    "input_img = Input(shape=(28, 28, 1))\n",
    "x = Flatten()(input_img)\n",
    "encoded = Dense(64, activation='relu')(x)\n",
    "\n",
    "# Define the decoder\n",
    "x = Dense(28 * 28 * 1, activation='sigmoid')(encoded)\n",
    "decoded = Reshape((28, 28, 1))(x)\n",
    "\n",
    "# Create the autoencoder model\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a500e5d",
   "metadata": {},
   "source": [
    "-   Train the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274e4965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the autoencoder\n",
    "autoencoder.fit(X_train,\n",
    "                X_train,\n",
    "                epochs=50,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_split=0.2)\n",
    "print(\"Autoencoder training completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a84b8c7",
   "metadata": {},
   "source": [
    "-   Evaluate the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23f5ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the autoencoder\n",
    "import numpy as np\n",
    "reconstruction = autoencoder.predict(X_test)\n",
    "reconstruction_error = np.mean(np.square(X_test - reconstruction))\n",
    "print(f'Reconstruction Error: {reconstruction_error:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d927f7",
   "metadata": {},
   "source": [
    "-   Visualize the reconstructed images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb68a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the original and reconstructed images\n",
    "n = 10  # Number of images to visualize\n",
    "plt.figure(figsize=(10, 4))\n",
    "for i in range(n):\n",
    "    # Original image\n",
    "    plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(X_test[i].reshape(28, 28), cmap='gray')\n",
    "    plt.title(f'Original: {y_test[i]}')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Reconstructed image\n",
    "    plt.subplot(2, n, i + n + 1)\n",
    "    plt.imshow(reconstruction[i].reshape(28, 28), cmap='gray')\n",
    "    plt.title('Reconstructed')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c850aa",
   "metadata": {},
   "source": [
    "-   Save the autoencoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2be5ad",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Save the autoencoder model\n",
    "autoencoder.save('autoencoder_mnist.h5')\n",
    "print(\"Autoencoder model saved as 'autoencoder_mnist.h5'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99eb602e",
   "metadata": {},
   "source": [
    "## Hands-on Exercise\n",
    "\n",
    "Repeat the above steps with the CIFAR-10 dataset, which consists of 32x32 color images in 10 classes. The goal is to compress the images into a lower-dimensional representation and then reconstruct the original images.\n",
    "\n",
    "-   Load the CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e1bdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b589a34",
   "metadata": {},
   "source": [
    "-   Visualize some samples from the CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1424d322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some samples from the CIFAR-10 dataset\n",
    "plt.figure(figsize=(10, 4))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(X_train[i])\n",
    "    plt.title(f'Label: {y_train[i]}')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a69ebee",
   "metadata": {},
   "source": [
    "-   Define the autoencoder architecture for CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48898da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the encoder for CIFAR-10\n",
    "input_img = Input(shape=(32, 32, 3))\n",
    "# Add a Convolutional layer for better feature extraction\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Flatten()(x)\n",
    "encoded = Dense(256, activation='relu')(x)\n",
    "\n",
    "# Define the decoder for CIFAR-10\n",
    "x = Dense(32 * 32 * 3, activation='sigmoid')(encoded)\n",
    "# Add a Convolutional transpose layer to reconstruct the image\n",
    "from tensorflow.keras.layers import Reshape\n",
    "x = Reshape((4, 4, 128))(x)  # Reshape to match the last pooling layer's output\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "# Reshape the output to match the original image dimensions\n",
    "decoded = Reshape((32, 32, 3))(x)\n",
    "\n",
    "# Create the autoencoder model for CIFAR-10\n",
    "autoencoder_cifar = Model(input_img, decoded)\n",
    "autoencoder_cifar.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder_cifar.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bec8ba3",
   "metadata": {},
   "source": [
    "-   Train the autoencoder on CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702960d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the autoencoder on CIFAR-10\n",
    "autoencoder_cifar.fit(X_train,\n",
    "                      X_train,\n",
    "                      epochs=50,\n",
    "                      batch_size=256,\n",
    "                      shuffle=True,\n",
    "                      validation_split=0.2)\n",
    "print(\"Autoencoder for CIFAR-10 training completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aca49e8",
   "metadata": {},
   "source": [
    "-   Evaluate the autoencoder on CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb02f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the autoencoder on CIFAR-10\n",
    "reconstruction_cifar = autoencoder_cifar.predict(X_test)\n",
    "reconstruction_error_cifar = np.mean(np.square(X_test - reconstruction_cifar))\n",
    "print(f'Reconstruction Error for CIFAR-10: {reconstruction_error_cifar:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d994b96",
   "metadata": {},
   "source": [
    "-   Visualize the reconstructed images from CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14731b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the original and reconstructed images from CIFAR-10\n",
    "n = 10  # Number of images to visualize\n",
    "plt.figure(figsize=(10, 4))\n",
    "for i in range(n):\n",
    "    # Original image\n",
    "    plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(X_test[i])\n",
    "    plt.title(f'Original: {y_test[i]}')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Reconstructed image\n",
    "    plt.subplot(2, n, i + n + 1)\n",
    "    plt.imshow(reconstruction_cifar[i])\n",
    "    plt.title('Reconstructed')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "ML Workshop",
   "language": "python",
   "name": "ml_workshop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
