{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6f86995",
   "metadata": {},
   "source": [
    "\n",
    "# Introduction to Classification\n",
    "\n",
    "Supervised learning is a type of machine learning where the model learns from labeled data. In this context, **classification** is a specific type of supervised learning where the goal is to predict a categorical label for new observations based on past data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33f323b",
   "metadata": {},
   "source": [
    "## Classification vs. Regression\n",
    "\n",
    "Classification is distinct from regression, which predicts continuous values. In classification, the target variable $y$ is categorical, meaning it can take on a limited number of discrete values (e.g., \"spam\" or \"not spam\", \"cat\", \"dog\", or \"weasel\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27da1bd4",
   "metadata": {},
   "source": [
    "## Classification Types\n",
    "\n",
    "Broadly, classification can be divided into two types:\n",
    "\n",
    "-   **Binary Classification**: The target variable has two classes (e.g., \"yes\" or \"no\", \"spam\" or \"not spam\"). Numerically, this can always be represented as 0 and 1.\n",
    "-   **Multiclass Classification**: The target variable has more than two classes (e.g., \"cat\", \"dog\", \"weasel\"). In this case, the model predicts one of several possible categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e583539",
   "metadata": {},
   "source": [
    "## Classification Algorithms\n",
    "\n",
    "Classification algorithms are designed to learn from labeled data and make predictions about the class of new, unseen data. Some common algorithms include:\n",
    "\n",
    "-   **Logistic Regression**: Despite its name, it is used for binary classification. It models the probability that a given input belongs to a particular class.\n",
    "-   **k-Nearest Neighbors (k-NN)**: A non-parametric method that classifies a data point based on the classes of its nearest neighbors in the feature space.\n",
    "-   **Decision Trees**: A tree-like model that splits the data into subsets based on feature values, leading to a decision about the class label.\n",
    "-   **Support Vector Machines (SVM)**: A method that finds the hyperplane that best separates the classes in the feature space.\n",
    "-   More advanced algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5f7e69",
   "metadata": {},
   "source": [
    "## Key Concepts\n",
    "\n",
    "-   **Decision Boundaries**: The boundaries that separate different classes in the feature space. These boundaries are determined by the classification algorithm and can be linear or non-linear.\n",
    "-   **Probability vs. Hard Classification**: Some algorithms output probabilities for each class (e.g., logistic regression), while others provide a hard classification (e.g., k-NN). The output can be class labels or probabilities, depending on the algorithm and the method used to make predictions.\n",
    "-   **Output**: The output of a classification model can be either class labels (e.g., `predict()` in `scikit-learn`) or probabilities (e.g., `predict_proba()` in `scikit-learn`). The choice depends on the specific use case and the algorithm used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ada17f",
   "metadata": {},
   "source": [
    "## Practical Demonstration\n",
    "\n",
    "In this section, we will demonstrate how to perform classification using the Iris dataset, a classic dataset in machine learning. The Iris dataset contains measurements of iris flowers and their species, making it suitable for both binary and multiclass classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef98b563",
   "metadata": {},
   "source": [
    "### Binary vs. Multiclass Classification\n",
    "\n",
    "In the Iris dataset, we can perform both binary and multiclass classification. For binary classification we can consider only two species of iris flowers (e.g., \"setosa\" and \"versicolor\"), while for multiclass classification we can use all three species (\"setosa\", \"versicolor\", and \"virginica\").\n",
    "\n",
    "-   Loading the Iris dataset and filter out the 'virginica' species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c74972",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../../data/iris.csv\", header=0)\n",
    "df = df[df['species'] != 'virginica']\n",
    "\n",
    "X = df.drop(columns=['species'])\n",
    "y = df['species'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edea234d",
   "metadata": {},
   "source": [
    "-   Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcca151",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Visualize the dataset\n",
    "sns.pairplot(df, hue='species', palette='Set1')\n",
    "plt.title(\"Iris Dataset Pairplot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb054f0",
   "metadata": {},
   "source": [
    "-   Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2957b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values in each column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Encode categorical labels\n",
    "y = df['species'].astype('category').cat.codes\n",
    "print(\"Encoded labels:\", y.unique())\n",
    "# Features and target variable\n",
    "X = df.drop(columns=['species'])\n",
    "print(\"Feature columns:\", X.columns.tolist())\n",
    "print(\"Feature data types:\", X.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59578ef0",
   "metadata": {},
   "source": [
    "-   Split the dataset into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a292540e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"Training set size:\", len(X_train))\n",
    "print(\"Test set size:\", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f3cdea",
   "metadata": {},
   "source": [
    "-   Train a Logistic Regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f440e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Train a logistic regression model\n",
    "clf = LogisticRegression(max_iter=200)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2a3177",
   "metadata": {},
   "source": [
    "-   Evaluate the model's accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df708d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model's accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Binary classification accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b9e1b1",
   "metadata": {},
   "source": [
    "-   Plot decision boundaries (2D) using only 2 features (e.g. `petal length`, `petal width`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c831c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Select two features for visualization\n",
    "X_vis = X[['petal length (cm)', 'petal width (cm)']]\n",
    "X_train_vis, X_test_vis, y_train_vis, y_test_vis = train_test_split(X_vis, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b84b442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on the selected features\n",
    "clf_vis = LogisticRegression(max_iter=200)\n",
    "clf_vis.fit(X_train_vis, y_train_vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f35c1bd",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Plot decision boundaries\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "display = DecisionBoundaryDisplay.from_estimator(\n",
    "    estimator=clf_vis,\n",
    "    X=X_vis,\n",
    "    alpha=0.8,\n",
    "    grid_resolution=500,\n",
    "    response_method=\"predict\",\n",
    ")\n",
    "display.ax_.scatter(\n",
    "    df['petal length (cm)'], df['petal width (cm)'], c=df['species'].astype('category').cat.codes, edgecolor=\"black\"\n",
    ")\n",
    "plt.title('Decision Boundary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c8a5be",
   "metadata": {},
   "source": [
    "## Hands-on Exercises\n",
    "\n",
    "Use the Iris dataset to perform multiclass classification. You will need to load the dataset again, since we've filtered out the 'virginica' species in the previous section.\n",
    "\n",
    "-   Load the Iris dataset and perform multiclass classification using all three species.\n",
    "-   Exploratory Data Analysis (EDA).\n",
    "-   Select two of the most relevant features.\n",
    "-   Perform the train-test split.\n",
    "-   Train a logistic regression model for multiclass classification.\n",
    "-   Evaluate the model's accuracy.\n",
    "-   Plot decision boundaries (2D) using only the 2 features, `petal length` and `petal width`."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "ML Workshop",
   "language": "python",
   "name": "ml_workshop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
