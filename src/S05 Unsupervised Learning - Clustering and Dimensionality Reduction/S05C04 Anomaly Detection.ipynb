{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fd14668",
   "metadata": {},
   "source": [
    "# Anomaly Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657349fd",
   "metadata": {},
   "source": [
    "## Introduction to Anomaly Detection\n",
    "\n",
    "**Anomaly Detection** is the process of identifying patterns in data that do not conform to expected behavior. It is crucial in various fields such as fraud detection, network security, and fault detection. Anomalies can indicate critical incidents, such as a structural defect or a security breach, and detecting them early can prevent significant damage. Anomaly detection can be categorized into three main types:\n",
    "\n",
    "-   ****Supervised Anomaly Detection****: Requires labeled data where anomalies are known.\n",
    "-   ****Unsupervised Anomaly Detection****: Does not require labeled data and identifies anomalies based on the distribution of the data.\n",
    "-   ****Semi-supervised Anomaly Detection****: Uses a small amount of labeled data to guide the detection process.\n",
    "\n",
    "****Applications of Anomaly Detection**** Anomaly detection is widely used in various domains, including:\n",
    "\n",
    "-   ****Fraud Detection****: Identifying fraudulent transactions in banking and finance.\n",
    "-   ****Network Security****: Detecting intrusions or abnormal behavior in network traffic.\n",
    "-   ****Fault Detection****: Monitoring industrial systems to identify potential failures.\n",
    "-   ****Healthcare****: Detecting unusual patterns in patient data that may indicate health issues.\n",
    "\n",
    "****Challenges in Anomaly Detection**** Anomaly detection poses several challenges:\n",
    "\n",
    "-   ****High Dimensionality****: Data with many features can make it difficult to identify anomalies.\n",
    "-   ****Imbalanced Data****: Anomalies are often rare compared to normal instances, leading to class imbalance.\n",
    "-   ****Dynamic Environments****: Anomalies can change over time, requiring adaptive detection methods.\n",
    "\n",
    "****Common Techniques for Anomaly Detection****\n",
    "\n",
    "-   ****Statistical Methods****: Use statistical tests to identify outliers based on the distribution of the data.\n",
    "-   ****Machine Learning Methods****: Employ algorithms like clustering, classification, and neural networks to detect anomalies.\n",
    "-   ****Distance-Based Methods****: Measure the distance between data points to identify anomalies based on their proximity to normal instances.\n",
    "-   ****Density-Based Methods****: Identify anomalies based on the density of data points in a given region.\n",
    "-   ****Ensemble Methods****: Combine multiple anomaly detection techniques to improve robustness and accuracy.\n",
    "\n",
    "****Clustering for Anomaly Detection**** Clustering algorithms can be used for anomaly detection by grouping similar data points together. Anomalies are identified as points that do not belong to any cluster or are far from the nearest cluster center. Common clustering algorithms used for anomaly detection include:\n",
    "\n",
    "-   ****k-Means Clustering****: Groups data into k clusters and identifies anomalies as points that are far from their assigned cluster centers.\n",
    "-   ****DBSCAN (Density-Based Spatial Clustering of Applications with Noise)****: Groups data based on density and identifies anomalies as points that do not belong to any cluster.\n",
    "-   ****Hierarchical Clustering****: Builds a hierarchy of clusters and identifies anomalies based on their distance from the nearest cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ac94c1",
   "metadata": {},
   "source": [
    "### K-Means Clustering for Anomaly Detection\n",
    "\n",
    "K-Means clustering can be used for anomaly detection by following these steps:\n",
    "\n",
    "1.  ****Data Preparation****: Normalize or standardize the data to ensure that all features contribute equally to the distance calculations.\n",
    "2.  ****Clustering****: Apply the k-Means algorithm to cluster the data into k groups.\n",
    "3.  ****Distance Calculation****: Calculate the distance of each data point to its assigned cluster center.\n",
    "4.  ****Anomaly Identification****: Define a threshold distance (e.g., mean distance + 2 standard deviations) to classify points as anomalies if their distance exceeds this threshold.\n",
    "5.  ****Evaluation****: Validate the identified anomalies using domain knowledge or additional data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff33c1b",
   "metadata": {},
   "source": [
    "#### Example: K-Means Clustering for Anomaly Detection\n",
    "\n",
    "-   Create a synthetic dataset with clusters and some anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936e30b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_clusters = 5\n",
    "\n",
    "# Generate synthetic data\n",
    "X, _ = make_blobs(n_samples=300, centers=n_clusters,\n",
    "                  cluster_std=0.5, random_state=42)\n",
    "\n",
    "# Add some anomalies\n",
    "anomalies = np.array([[10, 10], [12, 12], [15, 15]])\n",
    "X = np.vstack((X, anomalies))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8715df",
   "metadata": {},
   "source": [
    "-   Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22150ee-1c66-48da-ade3-2f1250731681",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1], marker='o', label='Data Points')\n",
    "plt.title('Synthetic Data with Anomalies')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d89305",
   "metadata": {},
   "source": [
    "-   Apply K-Means clustering and identify anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da669ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2618c79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate distances to cluster centers\n",
    "distances = np.linalg.norm(X - kmeans.cluster_centers_[kmeans.labels_], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c707fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define threshold for anomalies\n",
    "threshold = np.mean(distances) + 2 * np.std(distances)\n",
    "# Identify anomalies\n",
    "anomalies = X[distances > threshold]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2f0104",
   "metadata": {},
   "source": [
    "-   Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf67075",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Plot results\n",
    "plt.scatter(X[:, 0], X[:, 1], c=kmeans.labels_, cmap='viridis',\n",
    "marker='o', label='Normal Data')\n",
    "plt.scatter(anomalies[:, 0], anomalies[:, 1], color='red', marker='x',\n",
    "            label='Anomalies')\n",
    "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], color='black',\n",
    "            marker='x', s=200, label='Cluster Centers')\n",
    "plt.title('K-Means Clustering for Anomaly Detection')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d404a22",
   "metadata": {},
   "source": [
    "## Evaluation of Anomaly Detection Models\n",
    "\n",
    "Evaluating the performance of anomaly detection models can be challenging due to the imbalanced nature of the data. Common evaluation metrics include:\n",
    "\n",
    "-   ****Precision****: The proportion of true anomalies among the detected anomalies.\n",
    "-   ****Recall****: The proportion of true anomalies that were correctly detected.\n",
    "-   ****F1 Score****: The harmonic mean of precision and recall, providing a balance between the two.\n",
    "-   ****ROC Curve****: A graphical representation of the true positive rate against the false positive rate at various threshold settings.\n",
    "-   ****AUC (Area Under the Curve)****: A single scalar value that summarizes the performance of the model across all thresholds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d568c462",
   "metadata": {},
   "source": [
    "## Example: DBSCAN for Anomaly Detection and Evaluation\n",
    "\n",
    "-   Create a synthetic dataset with clusters and anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792d8b7d-bc8e-4943-aa26-125355e0201f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "X_core, _ = make_blobs(\n",
    "    n_samples=600,\n",
    "    centers=[(-2, -2), (3, 3)],\n",
    "    cluster_std=[0.5, 0.6],\n",
    "    random_state=42,\n",
    ")\n",
    "# Add anomalies\n",
    "rng = np.random.RandomState(42)\n",
    "X_noise = rng.uniform(low=-6, high=6, size=(40, 2))\n",
    "X = np.vstack([X_core, X_noise])\n",
    "y_true = np.zeros(X.shape[0], dtype=int)\n",
    "y_true[-40:] = 1  # Last 40 points are anomalies\n",
    "\n",
    "# Shuffle the X and y_true data together\n",
    "df = np.hstack([X, y_true.reshape(-1, 1)])\n",
    "rng.shuffle(df)\n",
    "X, y_true = df[:, :-1], df[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c6bd28",
   "metadata": {},
   "source": [
    "-   Visualize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8984ebc0-5eaa-4c5f-9a83-a670156e342a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(X_core[:, 0], X_core[:, 1], marker='o', s=20, label='Data Points')\n",
    "plt.scatter(X_noise[:, 0], X_noise[:, 1], marker='x', s=60, label='Anomalies')\n",
    "plt.title('Synthetic Data and Anomalies')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17385373",
   "metadata": {},
   "source": [
    "-   Standardize features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0631d8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X_scaled = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9d8dd1",
   "metadata": {},
   "source": [
    "-   Fit DBSCAN Clustering Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9224e940",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "dbscan = DBSCAN(eps=0.25, min_samples=8)\n",
    "labels = dbscan.fit_predict(X_scaled)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e53696",
   "metadata": {},
   "source": [
    "-   Collect results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee34f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "core_mask     = labels != -1        # regular points\n",
    "anomaly_mask  = labels == -1        # DBSCAN calls these “noise”\n",
    "\n",
    "print(f\"Detected {anomaly_mask.sum()} anomalies out of {X.shape[0]} total points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96169cc0",
   "metadata": {},
   "source": [
    "-   Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0085db",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "ax.scatter(*X[core_mask].T,  marker='o', s=20, label='normal')\n",
    "ax.scatter(*X[anomaly_mask].T, marker='x', s=60, label='anomaly')\n",
    "ax.set_title(\"DBSCAN clustering & detected anomalies\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d91741",
   "metadata": {},
   "source": [
    "-   Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a06a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# ground-truth labels: 0 = normal, 1 = anomaly\n",
    "# y_true = np.zeros(X.shape[0], dtype=int)\n",
    "# y_true[-40:] = 1\n",
    "\n",
    "# model predictions: DBSCAN marks anomalies with label -1\n",
    "y_pred = (labels == -1).astype(int)\n",
    "\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(\n",
    "    y_true, y_pred,\n",
    "    target_names=[\"normal\", \"anomaly\"],\n",
    "    digits=3))\n",
    "\n",
    "# Visualize the confusion matrix\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion_matrix(y_true, y_pred), annot=True, fmt='d',\n",
    "            xticklabels=[\"normal\", \"anomaly\"], yticklabels=[\"normal\", \"anomaly\"],\n",
    "            cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "ML Workshop",
   "language": "python",
   "name": "ml_workshop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
